{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 2.6426, Val Loss: 5.9393, Val Accuracy: 0.0970\n",
      "Epoch 2/10, Train Loss: 1.2728, Val Loss: 3.2487, Val Accuracy: 0.3818\n",
      "Epoch 3/10, Train Loss: 0.6144, Val Loss: 2.4907, Val Accuracy: 0.3879\n",
      "Epoch 4/10, Train Loss: 0.3026, Val Loss: 3.0118, Val Accuracy: 0.4242\n",
      "Epoch 5/10, Train Loss: 0.1796, Val Loss: 1.9895, Val Accuracy: 0.5758\n",
      "Epoch 6/10, Train Loss: 0.0645, Val Loss: 1.6549, Val Accuracy: 0.5879\n",
      "Epoch 7/10, Train Loss: 0.0594, Val Loss: 2.0861, Val Accuracy: 0.5515\n",
      "Epoch 8/10, Train Loss: 0.0548, Val Loss: 2.0961, Val Accuracy: 0.5515\n",
      "Epoch 9/10, Train Loss: 0.0695, Val Loss: 2.3544, Val Accuracy: 0.4727\n",
      "Epoch 10/10, Train Loss: 0.0944, Val Loss: 1.7925, Val Accuracy: 0.5697\n",
      "Training Accuracy: 98.39%\n",
      "Validation Accuracy: 56.97%\n",
      "Testing Accuracy: 53.29%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import models, datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Dataset directory\n",
    "data_dir = './dataset'\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "\n",
    "# Calculate split sizes\n",
    "train_size = int(0.6 * len(dataset))\n",
    "val_size = int(0.2 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "# Split dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Define DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Load a pretrained ResNet model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the final layer for classification\n",
    "num_classes = len(dataset.classes)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training and validation\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Train Loss: {running_loss/len(train_loader):.4f}, \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f}, \"\n",
    "          f\"Val Accuracy: {correct/total:.4f}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'res_crop_classifier_cnn.pth')\n",
    "\n",
    "# Accuracy calculation function\n",
    "def calculate_accuracy(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations for evaluation\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Get predictions\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)  # Get the index of the max probability\n",
    "            \n",
    "            # Update counts\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total * 100  # Convert to percentage\n",
    "    return accuracy\n",
    "\n",
    "# Calculate accuracies for train, validation, and test sets\n",
    "train_accuracy = calculate_accuracy(model, train_loader, device)\n",
    "val_accuracy = calculate_accuracy(model, val_loader, device)\n",
    "test_accuracy = calculate_accuracy(model, test_loader, device)\n",
    "\n",
    "# Print the accuracies\n",
    "print(f\"Training Accuracy: {train_accuracy:.2f}%\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Mazay-Wali-Folder\\Machine Learning\\Crops-Classification\\env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\Psycho\\AppData\\Local\\Temp\\ipykernel_12284\\3985436904.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('res_crop_classifier_cnn.pth'))  # Load weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: coconut\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the saved model\n",
    "model = models.resnet18(pretrained=False)  # Recreate ResNet18 architecture\n",
    "num_classes = len(dataset.classes)  # Number of classes\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)  # Modify the final layer\n",
    "model.load_state_dict(torch.load('final_model.pth'))  # Load weights\n",
    "model = model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Define image transformations (must match the training preprocessing)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load and preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')  # Ensure 3 channels (RGB)\n",
    "    image = transform(image)  # Apply transformations\n",
    "    image = image.unsqueeze(0)  # Add batch dimension (1, 3, 224, 224)\n",
    "    return image\n",
    "\n",
    "# Predict function\n",
    "def predict(image_path, model, device, class_names):\n",
    "    image = preprocess_image(image_path).to(device)  # Preprocess and move to device\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)  # Forward pass\n",
    "        _, predicted = torch.max(outputs, 1)  # Get class index with highest score\n",
    "    return class_names[predicted.item()]  # Return class name\n",
    "\n",
    "# Class names from dataset\n",
    "class_names = dataset.classes\n",
    "\n",
    "# Test the model on an example image\n",
    "image_path = 'test.jpg'  # Replace with your image path\n",
    "predicted_class = predict(image_path, model, device, class_names)\n",
    "\n",
    "print(f\"Predicted class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
